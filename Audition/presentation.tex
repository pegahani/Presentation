%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass{beamer}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{xcolor}
\usepackage{tikz}
\usepackage[tikz]{bclogo}
\usepackage[absolute,overlay]{textpos}
\usepackage{tcolorbox}
\usepackage{makecell}
\usepackage{multirow}

\newcommand{\imp}[1]{{\color{red}{#1}}}
\newcommand{\remark}[1]{{\color{blue}{#1}}}
\newcommand{\atten}[1]{{\color{green}{#1}}}
\newcommand\Fontvi{\fontsize{9}{10.2}\selectfont}

\newcommand{\tfidf}{\emph{tf-idf}}
\newcommand{\NMF}{\emph{NMF}}

\definecolor{mygreen}{rgb}{0, 0.5, 0}
\newcommand{\PA}[1]{{\color{mygreen}{#1}}}

\usepackage[utf8]{inputenc}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[CRIStAL]{Concours Maître de Conférences\\ CRIStAL} % The short title appears at the bottom of every slide, the full title is only on the title page

\author{Pegah ALIZADEH} % Your name
\institute[GREYC] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{Université de Caen Normandie (GREYC) \\ \includegraphics[scale=0.08]{images/greyc} \\ % Your institution for the title page
\medskip
\textit{pegah.alizadeh@unicaen.fr} % Your email address
}
\date{22 May 2018} % Date, can be changed to a custom date

\begin{document}


\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

%\begin{frame}{Outline}
%\tableofcontents
%\end{frame}



%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------
\setbeamercolor{background canvas}{bg=blue!20}
\begin{frame}
	\begin{center}
	\textbf{Parcours Professionnel et Académique}
	\end{center}
\end{frame}
{\setbeamercolor{background canvas}{bg=white}
%------------------------------------------------

\begin{frame}{Formation et Expérience Professionnelle Avant la Thèse}

\begin{block}{Formation}
	\textbf{2001 - 2005} : Licence en Mathématique.\\
	Université Shahid Beheshti (Téhéran, Iran).\\
	\textbf{2006 - 2008} : Master en Mathématique. \\
	Université international d’Imam Khomeini (Qazvin-Iran).
\end{block}
%%%%
\begin{block}{Expérience Professionnelle}
\textbf{2008-2009}: Programmatrice et conceptrice de BDD.\\
Entreprise Soroush Ray Pardazan ( Karaj, Iran ).\\
\textbf{2010 - 2011}: Enseignante de Mathématiques. \\
Université de Payam Nur de Karaj et Université Azad de Karaj, Iran
\end{block}

\end{frame}
%-------------------------------------------------

\begin{frame}{Formation et Expérience Professionnelle}

\begin{block}{Formation}
\textbf{Février - Mai 2012}: Stage de recherche en génie logiciel.\\
Université libre de Bolzano ( Bolzano, Italie )\\
\textbf{2012-2016}: Doctorat en Informatique.\\
LIPN, Université Paris 13.
\end{block}

\begin{block}{Expérience Professionnelle}
\textbf{2015-2016, 2016-2017}: ATER.\\
LIPN, Université Paris 13. Université Paris Dauphine.\\
\textbf{2017-2018}: Post-Doctorante en Machine Learning - Traitement Automatique de Langues.\\
GREYC, Université de Caen, Normandie. 
\end{block}

\end{frame}
%------------------------------------------------
\begin{frame}{Thèse}

\begin{itemize} 
\item \textbf{Dates}: Octobre 2012 - Décembre 2016
\item \textbf{Lieu}: Laboratoire d’Informatique de Paris Nord (LIPN),
Université Paris 13.
\item \textbf{Intitulé}: Élicitation et planification dans les processus de
décision de Markov avec des récompenses inconnues.
\item \textbf{Directeur de thèse}: Yann Chevaleyre.
\item \textbf{Rapporteurs} : Nicolas MAUDET (Université Pierre et
Marie Curie), Bruno ZANUTTINI (Université de Caen).
\item \textbf{Jury}: Yann CHEVALEYRE, Jérôme LANG, Nicolas
MAUDET, Henry SOLDANO, Paolo VIAPPIANI, Bruno
ZANUTTINI
\end{itemize}
	
\end{frame}
%------------------------------------------------

\setbeamercolor{background canvas}{bg=blue!20}
\begin{frame}
	\begin{center}
	\textbf{Thèmes de Recherche}
	\end{center}
\end{frame}
{\setbeamercolor{background canvas}{bg=white}


\begin{frame}{Thémes de recherche et applications}
\input{themes.tex}
\end{frame}

%------------------------------------------------
\begin{frame}{Travaux effectués - Les Méthodes Élicitation}
\begin{block}{Contexte}
\imp{Prédire des informations incertains} dans le modèle \imp{en interrogeant} le décisionnaire de systèmes.
\begin{center}
communication avec l’utilisateur $\leftrightarrows$ \framebox{MOMDP} $\leftrightarrows$ la politique $\pi$
\end{center}
\end{block}


\begin{block}{Approches utilisés}
\begin{itemize}
\item On a developpé une approche itérative basée sur une function de valeur en utilisent des \imp{méthodes de clustering} pour generer des \imp{requ\^etes plus informatives}.
\item La frontier de Pareto des politiques non dominées est calculé offline. On genére des \imp{coupes}capables de réduire de manière significative le \imp{polytope des recompenses}.
\item Probleme de \imp{composition de \textit{web-service}}: identifier la politique qui maximise la qualité des service selon les préférences des utilisateurs.
%sélectionner laquelle service dans chaque service abstract tel que: les qualités des services convient les préférences des utilisateurs
\end{itemize}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%



\begin{frame}{Travaux effectués - Les Méthodes Élicitation}

\begin{block}{Résultats}
\begin{itemize}
\item On trouve la politique optimale avec \imp{$65 \% $  moins de communications }avec l’agent ou décideur de
systèmes
\item Notre méthode trouve la politique optimale  pour \imp{instances réeles de grande taille}.
%\item Nous sommes en mesure de trouver le sous-ensemble de services Web qui maximisent les préférences de l'utilisateur.
\end{itemize}
\end{block}

\begin{itemize}
\small
\item P. Alizadeh, Y. Chevaleyre et F. Lévy. \textit{Solving MDPs with Unknown Reward Using Nondominated Vector-Valued Functions}. \textbf{ECAI (STAIRS) 2016.}
\item P. Alizadeh, Y. Chevaleyre et F. Lévy. \textit{Advantage Based Value Iteration for Markov Decision Processes with Unknown Rewards}. \textbf{IJCNN 2016.}
\item P. Alizadeh, Aomar Osmani, Abdelghani Chibani, Yacine Amirat et Mohamed Essaid Khanouche. \textit{Interactive QoS-aware Services Selection for the Internet of Things}. \textbf{Soumis à IEEE TSMC.}
\end{itemize}


\end{frame}



%------------------------------------------------
%\begin{frame}{Travaux effectués - Les Méthodes Optimisation}
\begin{frame}{Travaux effectués - Minimax Regret }

%\textbf{Contexte}:
\begin{block}{Contexte}
\begin{itemize}
\item Comment gerer un context ou \imp{les récompenses sont incertaines}? On calcule la politique optimale selon la méthode de \imp{minimax regret}.
\end{itemize}
\end{block}


\begin{block}{Approches utilisés}
\imp{Benders Decomposition:}\\
	\vspace{-0.4cm}
\begin{center}
	\framebox{Master Programme} \\
	\vspace{0.1cm}
	Informations (politiques)~~~~~ $\downarrow$ ~~~~~ $\uparrow$ feed-backs (coupes)\\
	\vspace{0.1cm}
	\framebox{Slave Programme} 
\end{center}
\vspace{-0.5 cm}
\begin{overlayarea}{\textwidth}{2.75cm}
    \only<1>{
\begin{itemize}
\item Une \imp{procedure heuristique}: Générer des contraintes du programme linéaire aléatoirement au lieu de résoudre le programme linéaire exact.
\end{itemize}
      }
    \only<2>{
\begin{itemize}
\item On a développé un \imp{branch-and-bound amélioré} basé sur Benders Decomposition pour calculer la meilleure politique déterministe.
\item On a proposé une \imp{analyse théorique et expérimentale} des politiques déterministes pour MDP.
\end{itemize}
        }
\end{overlayarea}
\end{block}

\end{frame}

\begin{frame}{Travaux effectués - Minimax Regret }

\begin{block}{Résultats}
\begin{itemize}
\item La méthode heuristique est plus rapide et applicable sur les modèles de grande taille.
\item Dans un temps $8$ fois plus lent, on trouve la politique déterministe avec le regret 	$25 \%$ moins que la politique stochastique.  
\item théoriquement, on preuve que 
	$\frac{\text{regret pol. determinisé}}{\text{regret pol. déterministe}} = 2 $
\end{itemize}
\end{block}

\begin{itemize}
\small
\item  P. Alizadeh, Y. Chevaleyre et J. D. Zucker. \textit{Approximate regret based elicitation in Markov Decision Process}. \textbf{IEEE-RIVF 2015.} 
\item Pegah Alizadeh, Emiliano Traversi et Aomar Osmani. \textit{Deterministic Solutions Based on Maximum Regrets in Markov Decision Processes with Imprecise Rewards}. \textbf{Soumis à ECML 2018.}
\end{itemize}

\end{frame}
%------------------------------------------------



%------------------------------------------------
%\begin{frame}{Travaux effectués - Les Méthodes Optimisation}
%
%
%
%\begin{itemize}
%
%\item \textbf{Résultat}: 
%\item \textbf{Calculer les politique déterministes}: proposer un branch-and-bound basé sur le Benders decomposition. %comme bounding procedure.
%\item \textbf{Résultat} [soumis à ECML 2018]: 
%	\begin{itemize}
%	\item Dans un temps $8$ fois plus lent, on trouve la politique déterministe avec le regret 	$25 \%$ moins que la politique stochastique   
%	\item Théocratiquement, on preuve que 
%	$$\frac{\text{regret de politique stochastic}}{\text{regret de politique deterministe}} = 2 $$
%	\end{itemize}
%\end{itemize}
%
%\end{frame}

%%------------------------------------------------
%\begin{frame}{Travaux effectués \\ Les Applications et les réseaux de neurones}
%
%\begin{columns}
%\begin{column}{0.6\textwidth}
%   
%	\textbf{Contexte}: Composition de web service\\
%	\vspace{0.2cm}
%	\textbf{Question}: Il faut sélectionner laquelle service dans chaque service abstract tel que: les qualités des services convient les préférences des utilisateurs%, Et minimiser l’énergie totale consommée par les services sélectionnés  
%\\	
%	\vspace{0.2cm}
%	\textbf{Approche}: Modéliser la probleme comme une MDP avec des objectives de qualité de service et Implémenter l'algorithme d'ABVI.
%\end{column}
%\begin{column}{0.4\textwidth}  %%<--- here
%    \begin{center}
%     \includegraphics[width=0.8\textwidth]{images/web-service}
%     \end{center}
%\end{column}
%\end{columns}
%
%\end{frame}


%------------------------------------------------
%------------------------------------------------
\begin{frame}{Travaux effectués - TAL - Compte rendu de Réunion }
\vspace{-0.3cm}
\begin{block}{Contexte}
	\begin{center}
     \includegraphics[width=0.55\textwidth]{images/reus-image} \\
	\end{center}
\vspace{-0.5cm}
\begin{itemize}
\item Extraire les \imp{informations importants} à partire des \imp{transcriptions de réunions} (comme projet, décisions, problèmes lies a projets, etc.)
\end{itemize}
\end{block}


\begin{block}{Approches utilisés}
\begin{itemize}
%	\item Application des méthodes topic modeling et tf-idf.
	\item \imp{Regroupement des réunions} avec les méthodes topic modeling et tf-idf.
	\item \imp{Caractérisations de chaque réunions} avec la méthode topic modeling. 
	\item \imp{Identification des actes de dialogues} avec les méthodes non-supervisées et apprentissage profond (comme LSTM).
\end{itemize}
\end{block}
\end{frame}


\begin{frame}{Travaux effectués - TAL - Compte rendu de Réunion }

\begin{block}{Résultats}
\begin{itemize}
\item Topic modeling  et tf-idf sont \imp{complémentaire}. 
\item \imp{topic modeling} est meilleure pour la \imp{synthèse et l'extraction de thème}.
\item \imp{tf-idf} fonctionne bien sur les \imp{caractérisations de réunion}.
\end{itemize}
\end{block}

\begin{itemize}
\small
\item Pegah Alizadeh, Peggy Cellier, Bruno Crémellieux, Thierry Charnois et Albrecht Zimmermann. \textit{An Experimental Approach For Information Extraction in Multi-Party Dialogue Discourse}. \textbf{CICLING 2018.}
\item Pegah Alizadeh, Peggy Cellier, Bruno Crémellieux, Thierry Charnois et Albrecht Zimmermann. \textit{An Unsupervised Learning Approach for Dialogue Act Tagging in Multi-Party Dialogues}. \textbf{En préparation.}
\end{itemize}

\end{frame}
%------------------------------------------------
%------------------------------------------------

%%------------------------------------------------
%\begin{frame}{Travaux effectués - TAL \\ Compte rendu de Réunion}
%\vspace{-0.5cm}
%	\begin{center}
%     \includegraphics[width=0.7\textwidth]{images/reus-image} \\
%	\end{center}
%%
%
%\textbf{Contexte}: Extraire des informations importants et structurés de réunions comme le projet, décisions, problèmes lies a projets et etc. \\
%
%\textbf{Plusieurs Approches}:
%\begin{itemize}
%	\item regroupement des réunions avec les méthodes topic modeling et tf-idf. 
%	\item extraire des informations caractérisations de chaque réunions avec le tf-idf. 
%	\item Identification des actes de dialogues avec les méthodes non-supervisées et apprentissage profond (comme LSTM)
%\end{itemize}
%
%\end{frame}
%



%------------------------------------------------
%------------------------------------------------
\begin{frame}{Travaux effectués - Reconstruction du parcours professionnelle}
\begin{block}{Contexte}
Recherche des informations et entités nomes dans les documents en l'internet 
\begin{center}
 nom d'expert $\longrightarrow$ \framebox{Système} $\longrightarrow$ parcours professionnelle d'experte  
\end{center}
\end{block}

\begin{block}{Approches utilisés}
\begin{itemize}
\item \textbf{Approche de RL profond}: Modéliser le problème comme une MDP et trouver le meilleurs parcours avec  algorithm de Deep Q-network.  
\end{itemize}
\end{block}
\end{frame}


\begin{frame}{Travaux effectués - Reconstruction du parcours professionnelle}

\begin{block}{Résultats}
\begin{itemize}
\item On arrive à extraire le parcours professionnelle de chaque personne avec une bonne precision et en générant moins des requêtes sur le moteurs de recherche.  
\end{itemize}
\end{block}

\begin{itemize}
\small
\item  Pegah Alizadeh, Jorge Garcia Flores, Ivan Vladimir Meza Ruiz, Luis Pineda Cortes.
\textit{Cartography of the diaspora of knowledge by semantic search of the web.} \textbf{En préparation.}
\end{itemize}

\end{frame}
%------------------------------------------------
%------------------------------------------------


%%------------------------------------------------
%\begin{frame}{Travaux effectués \\ Les Applications et les réseaux de neurones}
%\textbf{Contexte}: Recherche des informations et entités nomes dans les documents en l'internet 
%\begin{center}
% nom d'expert $\longrightarrow$ \framebox{Système} $\longrightarrow$ parcours professionnelle d'experte  
%\end{center}
%\textbf{Approche de RL profond}: Modéliser le problème comme une MDP et trouver le meilleurs parcours avec  algorithm de Deep Q-network. 
%
%\textbf{Résultat}: On arrive à extraire le parcours professionnelle de chaque personne avec une bonne precision et en générant moins des requêtes sur le moteurs de recherche.  
%\end{frame}


%------------------------------------------------
%\begin{frame}{publications}
%Articles acceptés:\\
%\begin{itemize}
%
%\item [1] Pegah Alizadeh, Peggy Cellier, Bruno Crémellieux, Thierry Charnois et Albrecht Zimmermann. An Experimental Approach For Information Extraction in Multi-Party Dialogue Discourse, \textbf{CICLING 2018}\\
%
%
%\item [2] P. Alizadeh, Y. Chevaleyre et F. Lévy. Solving MDPs with Unknown Reward Using Nondominated Vector-Valued Functions. \textbf{ECAI (STAIRS) 2016}\\
%
%
%\item [3] P. Alizadeh, Y. Chevaleyre et F. Lévy. Advantage Based Value Iteration for Markov Decision Processes with Unknown Rewards.\textbf{IJCNN 2016}\\
%
%\item [4] P. Alizadeh, Y. Chevaleyre et J. D. Zucker. Approximate regret based elicitation in Markov Decision Process. \textbf{IEEE-RIVF 2015} \\
%
%\end{itemize}
%
%\end{frame}
%%------------------------------------------------
%\begin{frame}{publications}
%
%Articles soumis:\\
%
%\begin{itemize}
%	\item Pegah Alizadeh, Emiliano Traversi et Aomar Osmani. Deterministic Solutions Based on Maximum Regrets in Markov Decision Processes with Imprecise Rewards. %, \textbf{ECML 2018}
%	\item Pegah Alizadeh, Aomar Osmani, Abdelghani Chibani, Yacine Amirat et Mohamed Essaid Khanouche. Interactive QoS-aware Services Selection for the Internet of Things.
%\end{itemize}
%
%Articles en préparation:\\
%\begin{itemize}
%	\item Pegah Alizadeh, Peggy Cellier, Bruno Crémellieux, Thierry Charnois et Albrecht Zimmermann. An Unsupervised Learning Approach for Dialogue Act Tagging in Multi-Party Dialogues. 
%\end{itemize}
%
%\end{frame}

%------------------------------------------------
\input{projet-recherche.tex} 

%------------------------------------------------

\setbeamercolor{background canvas}{bg=blue!20}
\begin{frame}
	\begin{center}
	\textbf{Enseignement}
	\end{center}
\end{frame}
{\setbeamercolor{background canvas}{bg=white}

%-----------------------------------------------
\begin{frame}{Enseignement avant et durant la Thèse}
\begin{block}{Avant la Thèse (2,5 ans aux universités en Iran)}
Différents cours en \textbf{mathématique et statistique} aux étudiants de licence et ingénierie en informatique, statistique et économie.
\begin{itemize}
\item Precalculus, Calculus I, Calculus II. Equations Différentielles Ordinaires. Statistiques. Algèbre Linéaire Numérique.
\end{itemize}
\end{block}

\begin{block}{Durant la thèse (2 ans Monitrice -- 128 heurs)}
Des étudiants de 1ère et 2ème année en \textbf{Informatique à l'IUT} de Paris 13.

\begin{itemize}
\item Programmation (C++). Programmation et administration des BDD (Postgresql). Introduction aux interfaces homme- machine (Java,swing).
\end{itemize}
\end{block}

\end{frame}

%------------------------------------------------

\input{projet-teaching.tex}
%------------------------------------------------
%\begin{frame}
%\frametitle{References}
%\footnotesize{
%\begin{thebibliography}{99} 
%
%\bibitem[Narasimhan et al., 2016]{Narasimhan}Karthik Narasimhan, Adam Yala and Regina Barzilay. (2016)
%\newblock Improving Information Extraction by Acquiring External Evidence with
%Reinforcement Learning. 
%\newblock \emph{EMNLP}
%%%
%\bibitem[Benavent et Zanuttini, 2017]{Kim2015} Florian Benavent and Bruno Zanuttini. (2017)
%\newblock An Experimental Study of Advice in Sequential Decision-Making under
%Uncertainty
%\newblock \emph{AAAI}
%%%
%\bibitem[Kim et al.2016]{Kim2016} Weng, P., and Zanuttini, B.(2013)
%\newblock Interactive value iteration for Markov decision processes with unknown rewards.
%\newblock \emph{23rd International Joint Conference on Artificial Intelligence (IJCAI 2013)}
%%%
%
%%\bibitem[]{}
%%\newblock
%%\newblock \emph{}
%\end{thebibliography}
%}
%\end{frame}

\end{document} 
